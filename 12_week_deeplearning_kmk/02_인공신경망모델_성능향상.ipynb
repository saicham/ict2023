{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2d7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d5278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "### 데이터 읽어 들이기\n",
    "(train_input, train_target), (test_input, test_target) = \\\n",
    "     keras.datasets.fashion_mnist.load_data()\n",
    "    \n",
    "print(train_input.shape, train_target.shape)    \n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2543c613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 정규화 하기\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea56f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 픽셀 데이터를 1차원으로 만들기\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec222d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000,)\n",
      "(12000, 784) (12000,)\n"
     ]
    }
   ],
   "source": [
    "### 훈련 및 검증데이터로 분류하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = \\\n",
    "         train_test_split(train_scaled, train_target,\n",
    "                          test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_scaled.shape, train_target.shape)\n",
    "print(val_scaled.shape, val_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba53c1",
   "metadata": {},
   "source": [
    "# 인공신경망 모델에 신경망층 추가 방법(3가지)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e1123",
   "metadata": {},
   "source": [
    "### 1. 신경망층 추가방법(1)\n",
    "##### - 층을 먼저 만들고, 신경망 모델 생성시 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761fb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 입력층 생성하기\n",
    "### 784의 입력데이터를 이용해서 손실이 적은 100개 추출\n",
    "dense1 = keras.layers.Dense(100, activation=\"sigmoid\",\n",
    "                            input_shape=(784,))\n",
    "\n",
    "### 출력계층 생성하기\n",
    "### 입력계층을 통해 추출된 100개 데이터를 입력으로 받아서\n",
    "#    최종 10개로 분류(확률적으로 분류됨)\n",
    "# 출력계층의 활성화 함수 : sigmoid와 softmax 둘중 하나 사용\n",
    "dense2 = keras.layers.Dense(10, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e48688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17c9682ae50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 심층신경망 만들기(신경망층이 여러개인 경우, 심층신경망이라고 칭함)\n",
    "### 모델생성\n",
    "model = keras.Sequential([dense1, dense2])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74baa8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 모델 구조 확인하기\n",
    "model.summary()\n",
    "\n",
    "### dense1 파라미터 갯수 = 784 * 100 +100 = 78500\n",
    "### dense2 파라미터 갯수 = 100 * 10 + 10 = 1010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9b147",
   "metadata": {},
   "source": [
    "### 2. 신경망 계층 추가방법(2)\n",
    "##### - 신경망 모델 생성시에 신경망층 함께 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abff0129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17c96b2f4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(100, activation=\"sigmoid\",\n",
    "                                             input_shape=(784,), name=\"hidden-layer\"),\n",
    "                          keras.layers.Dense(10, activation=\"softmax\", name=\"out-layer\")], name=\"Model\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "503c3df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden-layer (Dense)        (None, 100)               78500     \n",
      "                                                                 \n",
      " out-layer (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 모델 구조 확인하기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb89898",
   "metadata": {},
   "source": [
    "### 3. 신경망 계층 추가방법(3)\n",
    "##### - 신경망모델 생성후, add()함수를 이용해서 계층 추가\n",
    "##### - 가장 많이 사용되는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7833f4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17c965acc70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400fd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. 생성된 모델에 계층 추가하기\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\",\n",
    "                                             input_shape=(784,)))\n",
    "\n",
    "model.add( keras.layers.Dense(10, activation=\"softmax\"))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156e3eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 모델 구조 확인하기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b3478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. 모델 설정하기(compile)\n",
    "### - 손실함수 : 다중분류(숫자) 사용\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5322a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 0.5691 - accuracy: 0.8067\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.4102 - accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 0.3739 - accuracy: 0.8643\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.3521 - accuracy: 0.8715\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 0.3360 - accuracy: 0.8779\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 0.3215 - accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 0.3105 - accuracy: 0.8869\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 0.2998 - accuracy: 0.8920\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 0.2898 - accuracy: 0.8945\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 524us/step - loss: 0.2828 - accuracy: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c97021af0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 4. 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cf24b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 406us/step - loss: 0.3263 - accuracy: 0.8828\n",
      "손실율 =  0.3262518346309662  / 정확도 =  0.8828333616256714\n"
     ]
    }
   ],
   "source": [
    "### 검증(평가) 하기\n",
    "score = model.evaluate(val_scaled, val_target)\n",
    "print(\"손실율 = \", score[0], \" / 정확도 = \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "< 손실함수(loss function) >\n",
    " - 손실함수는 실제값과 예측값의 차이를 수치화해주는 함수\n",
    " - 이 두값의 차이, 즉, 오차가 클수록 솜실함수의 값은 크고,\n",
    "                       오차가 작을수록 손실함수의 값은 작음\n",
    " - \"회귀\"와 같이 연속 데이터를 사용하는 경우에는 \"평균제곱오차\" 사용\n",
    " - \"분류\"에서는 크로스 엔트로피를 주로 사용\n",
    " - 딥러닝의 학습 과정은 손실함수의 값이 최소화 되는 지점의\n",
    "   가중치와 편향을 찾는 것이 목적임\n",
    "\n",
    "< 손실 함수로 사용되는 함수들 >\n",
    " 1. MSE(Mean Squared Error, 평균제곱오차)\n",
    "  - 연속형 변수를 예측할 때 사용됨\n",
    "  - compile()함수에서 loss 속성에 \"mse\" 라고 작성하여 사용함\n",
    "  \n",
    " 2. Categorical Corssentropy\n",
    "  - 다중분류 시에 사용됨\n",
    "  - target 데이터의 형태가 원-핫 인코딩된 형태인 경우 사용\n",
    "  \n",
    " 3. Binary Crossentropy\n",
    "  - target 데이터의 분류형태가 0 또는 1과 같이 이진분류시 사용됨\n",
    "  - 출력층의 활성화함수로 시그모이드(sigmoid) 함수를 사용함\n",
    "  \n",
    " 4. Sparse Categorical Croessentropy\n",
    "  - target 데이터의 형태가 0, 1, 2...와 같은 숫자형태인 경우 사용\n",
    "  - 출력층의 활성화 함수로는 소프트맥스(softmax) 함수를 사용함\n",
    "  \n",
    " ** 주로 3번과 4번이 많이 사용됨  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fe4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "< 활성화 함수 (Activation Function) >\n",
    " - 손실에 따른 출력을 담당하는 함수\n",
    " - 데이터를 결정하기 위한 함수로 \n",
    "   -> 중간단계의 계층(은닉층)에서 출력 갯수에 맞는 결과를 결정하기 위한 \n",
    "      활성화 함수가 사용되며,\n",
    "   -> 출력단계의 계층(출력층)에서는 최종 target 데이터를 결정하기 위한\n",
    "      활성화함수가 사용됨\n",
    "   \n",
    "< 사용되는 활성화 함수 >\n",
    " 1. 시그모이드(Sigmoid) 함수\n",
    "  - logistic function 이라고도 함\n",
    "  - 시그모이드 함수의 결과값이 0과 1 사이의 값으로 결정하게 됨\n",
    "  - y의 값이 0.5를 기준으로 0.5보다 크면 1, 작으면 0으로 결정\n",
    "  - 이진분류시에 주로 사용됨\n",
    "  - 손실함수는 Binary Crossentropy 사용\n",
    "  \n",
    " 2. Tanh(Hypterbolic Tangent) 함수\n",
    "  - 시그모이드 함수의 향상된 함수\n",
    "  - -1에서 1사이의 값으로 결정하게 됨\n",
    "  - 0보다 크면 1, 음수의 갑ㅄ은 모두 0으로 결정하게 됨\n",
    "  - 시그모이드보다 결정 범위가 크기에 학습이 효율적이라고 평하고 있음\n",
    "  - 중간 계층에 주로 사용\n",
    "  \n",
    " 3. 렐루(ReLU, Rectified Linear Unit) 함수\n",
    "  - 0과 1의 값으로 처리\n",
    "  - 0보다 작으면 모두 0으로, 0보다 크면 1로 처리함\n",
    "  - 0보다 작은 값이 발생하지 않는다는 장점이 있음\n",
    "  - 중간 계층에 주로 사용\n",
    "  \n",
    " 4. 소프트맥스(SoftMax) 함수\n",
    "  - 0.0에서 1.0 사이의 실수의 범위로 사용\n",
    "  - 여러개의 target값 중에 가장 높은 결정값을 선택하게 되며,\n",
    "  - 여래개의 target값 들은 0.0~1.0 사이의 확률로 나타남\n",
    "  - target 값의 모든 값의 합은 1.0이 됨\n",
    "  - 출력층에 주로 사용\n",
    "  - 손실계수로는 Sparse Categorical Croessentropy가 사용됨\n",
    "  \n",
    " 5. Leaky ReLU\n",
    "  - ReLU의 향상된 함수\n",
    "  - 0보다 작은 값들을 허용하게 하여 훈련의 효율을 높였음\n",
    "  \n",
    "### 딥러닝 계층을 사용하는 방법\n",
    " - 1. 다른 누군가가 만들어 놓은 모델을 그대로 사용\n",
    " - 2. 계층을 추가 또는 수정 또는 제거하면서\n",
    " - 3. 사용하는 데이터에 가장 적함한(정확도가 높은) 모델을 완성\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad8246",
   "metadata": {},
   "source": [
    "# 전처리 계층 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdbf5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "\n",
    "### 전처리계층 추가하기\n",
    "# - 훈련에 사용되지는 않음\n",
    "# - Flatten()\n",
    "#     : 1차원으로 만들어주는 계층     *** 중요 ***\n",
    "#     : 입력 차원을 모두 일렬로 펼치는 역할 수행\n",
    "#     : 입력에 곱해지는 가중치나 절편이 없음\n",
    "#     : 인공 신경망의 성능에 기여하지 않음(훈련에 사용되지 않음의 의미)  *** 중요 ***\n",
    "#     : 입력층과 은닉층 사이에 위치함\n",
    "#     : 보통 입력층 바로 뒤에 위치하는 것이 일반적임\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))    # 1차원으로 만든거라고 함\n",
    "\n",
    "### 은닉계층(hidden layer) 추가하기\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "\n",
    "### 출력계층(output layer) 추가하기\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "### 훈련에 사용되는 신경망층은 2개임\n",
    "# - 전처리 계층은 훈련에 포함되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e77922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8871fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "(60000, 28, 28)\n",
      "(48000, 28, 28) (48000,)\n",
      "(12000, 28, 28) (12000,)\n"
     ]
    }
   ],
   "source": [
    "### 데이터 읽어 들이기\n",
    "(train_input, train_target), (test_input, test_target) = \\\n",
    "     keras.datasets.fashion_mnist.load_data()\n",
    "    \n",
    "print(train_input.shape, train_target.shape)    \n",
    "print(test_input.shape, test_target.shape)\n",
    "\n",
    "### 정규화 하기\n",
    "train_scaled = train_input / 255.0\n",
    "print(train_scaled.shape)\n",
    "\n",
    "### 훈련 및 검증데이터로 분류하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = \\\n",
    "         train_test_split(train_scaled, train_target,\n",
    "                          test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_scaled.shape, train_target.shape)\n",
    "print(val_scaled.shape, val_target.shape)\n",
    "\n",
    "### 픽셀 데이터를 1차원으로 만드는 것은\n",
    "# - 모델 생성시 만든 전처리계층인 Flatern 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72190c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 컴파일 : 훈련모델 손실함수 설정\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f535584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 0.5348 - accuracy: 0.8137\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 0.3952 - accuracy: 0.8581\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 0.3559 - accuracy: 0.8729\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 0.3344 - accuracy: 0.8805\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 0.3199 - accuracy: 0.8864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c94463e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee9b29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 381us/step - loss: 0.3532 - accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3531873822212219, 0.8791666626930237]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 검증(평가)하기\n",
    "score = model.evaluate(val_scaled, val_target)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5c5a588",
   "metadata": {},
   "source": [
    "### 옵티마이저를 이용한 모델 클래스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "< 옵티마이저(optimizer) >\n",
    " - 딥러닝에서 빠르고 정확하게 학습하는 것을 목표로 나온 속성\n",
    " - 주로 경사하강법(Gradient Descent Algorithm) 기반의 알고리즘을 지정\n",
    " - 경사하강법의 옵티마이저 :  SGD 기반으로 딥러닝 모델들이 향상되고 있음\n",
    " - 다양한 경사하강법 알고리즘들이 있음\n",
    " - compile() 함수에 설정함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "527e5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 경사하강법을 적용\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")\n",
    "\n",
    "\n",
    "### 위와 동일\n",
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습율(learning_rate)\n",
    "# - 기본값은 0.01   # --> 값을 작게할수록 훈련시간이 오래걸린다고 함\n",
    "# - 값이 커질수록 훈련 강도를 낮아지게 됨\n",
    "# - 가중치를 최적화하는데 있어서, 학습율의 값은 매우 중요하게 적용됨\n",
    "# - 학습율의 값은 하이퍼파라메터 튜닝을 통해 찾아내어 작성할 수도 있음\n",
    "# - 학습율은 경사를 내려오면서 얼마만큼 이동할 것인지를 결정하는 값임\n",
    "#   (사람의 걸음걸이 중 보폭 이라고 생각하시면 됩니다...)\n",
    "\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모멘텀(momentum)\n",
    "# - 학습율과 동일하게 최적화 알고리즘임\n",
    "# - 물릭학에서 사용하는 운동량과 동력을 뜻함\n",
    "# - 랜덤하게 지그재그로 내려오면서 최적화(최단경사 이동거리)되는 것을\n",
    "#   해결하기 위해서 나온 알고리즘\n",
    "# - ** 관성과 가속도를 적용한 알고리즘임 **\n",
    "# - 이동하던 한 방향으로 좀 더 이동할 수 있도록 하기 위해 적용된 개념\n",
    "\n",
    "### 모멘텀 중요 특징\n",
    "# - 현재 이동하는 방향과는 별개로, 과거에 이동했던 방향을 기억하고 있음\n",
    "# - 과거의 방향으로 일정량(학습율)을 추가하여 이동을 하게됨\n",
    "# - 메모리 사용량이 많아지는 단점이 있음\n",
    "\n",
    "### nesterov(네스테로프)\n",
    "# - 모멘텀 최적화의 변종 알고리즘\n",
    "# - 현재 위치가 아니라,\n",
    "#   모멘텀의 방향으로 조금 앞서서 경사를 계산\n",
    "\n",
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd56e1",
   "metadata": {},
   "source": [
    "### 적응적 학습율(adaptive learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델이 최적점(목표하는 지점)에 다달았을 때 학습률(보폭)을\n",
    "#   낮추게 되면, 안정적으로 최적점에 도달(수렴)할 것이라는 가능성이\n",
    "#   높아진다는 개념에서 나온 알고리즘\n",
    "# - 케라스 모델이 자동으로 학습율을 조정하게됨\n",
    "# - 학습율을 자동으로 조정하는 것을 \"적응적 학습율\" 이라고 칭합니다.\n",
    "#   (사람이 직접 처리해 주지 않아도 됨)\n",
    "# - 적응적학습율의 기본 학습율은 0.01임  #--> 디폴트로 쓰는게 가장 좋음\n",
    "# - 적응적 학습율을 적용한 알고리즘\n",
    "#    : adagrad, rmsprop, adam\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 적응적학습율의 디폴트 알고리즘은 rmsprop임\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5080d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam()\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2af906c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 인공신경망 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "\n",
    "### 전처리 계층 추가하기\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "### 훈련계층(은닉계층) 추가하기\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "\n",
    "### 출력계층 추가하기\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f9f605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compile 설정하기\n",
    "# adam 적용적 학습율 적용\n",
    "# - adam : 방향과 학습율 두가지 모두를 적절하게 처리하기 위한 알고리즘\n",
    "# - 옵티마이저로 가장 먼저 적용하면 좋음\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fe23617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 477us/step - loss: 0.5245 - accuracy: 0.8179\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 460us/step - loss: 0.3909 - accuracy: 0.8605\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 463us/step - loss: 0.3510 - accuracy: 0.8723\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 459us/step - loss: 0.3244 - accuracy: 0.8809\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 458us/step - loss: 0.3043 - accuracy: 0.8888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c93cc4dc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ff91a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 364us/step - loss: 0.3293 - accuracy: 0.8781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32925283908843994, 0.878083348274231]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 검증(평가)하기\n",
    "score = model.evaluate(val_scaled, val_target)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46142871",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 옵티마이저 3가지를 처리하면서 최저손실율과 최대정확도 찾아보기\n",
    "def getBestEval(opt, epoch) :\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=\"accuracy\")\n",
    "    model.fit(train_scaled, train_target, epochs=epoch)\n",
    "    rs_eval = model.evaluate(val_scaled, val_target)\n",
    "    return rs_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1886e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 1s 460us/step - loss: 1.1964 - accuracy: 0.6345\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 469us/step - loss: 0.7800 - accuracy: 0.7503\n",
      "375/375 [==============================] - 0s 387us/step - loss: 0.7370 - accuracy: 0.7584\n",
      "opt= adagrad  | rs= [0.7369889616966248, 0.7584166526794434]\n",
      "best_loss_opt= adagrad  | best_loss= 0.7369889616966248  | rs[0]= 0.7369889616966248\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 0.5405 - accuracy: 0.8110\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.3948 - accuracy: 0.8595\n",
      "375/375 [==============================] - 0s 367us/step - loss: 0.3796 - accuracy: 0.8624\n",
      "opt= rmsprop  | rs= [0.3795769512653351, 0.862416684627533]\n",
      "best_loss_opt= rmsprop  | best_loss= 0.3795769512653351  | rs[0]= 0.3795769512653351\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 1s 462us/step - loss: 0.5204 - accuracy: 0.8207\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 463us/step - loss: 0.3915 - accuracy: 0.8603\n",
      "375/375 [==============================] - 0s 376us/step - loss: 0.3793 - accuracy: 0.8633\n",
      "opt= adam  | rs= [0.3793168067932129, 0.8632500171661377]\n",
      "best_loss_opt= adam  | best_loss= 0.3793168067932129  | rs[0]= 0.3793168067932129\n",
      " 0.0 / adam 0.3793168067932129\n"
     ]
    }
   ],
   "source": [
    "### 옵디마니저 3가지 실행\n",
    "optimizers = [\"adagrad\", \"rmsprop\", \"adam\"]\n",
    "best_eval = 0.0\n",
    "best_opt = \"\"\n",
    "\n",
    "best_loss = 1.0\n",
    "best_loss_opt = \"\"\n",
    "\n",
    "for opt in optimizers :\n",
    "    rs = getBestEval(opt, 2)\n",
    "    print(\"opt=\", opt, \" | rs=\", rs)\n",
    "    \n",
    "    ### 가장 낮은 손실율과 이때 옵티마이저 확인하기\n",
    "    if best_loss > rs[0] :\n",
    "        best_loss = rs[0]\n",
    "        best_loss_opt = opt\n",
    "        print(\"best_loss_opt=\", best_loss_opt,\n",
    "             \" | best_loss=\", best_loss,\n",
    "             \" | rs[0]=\", rs[0])\n",
    "        \n",
    "    \n",
    "    ### 가장 낮은 정확도와 이때 옵티마이저 확인하기\n",
    "    if best_eval > rs[1] :\n",
    "        best_eval = rs[1]\n",
    "        best_opt = opt\n",
    "        print(\"best_loss_opt=\", best_opt,\n",
    "             \" | best_loss=\", best_eval,\n",
    "             \" | rs[0]=\", rs[1])\n",
    "    \n",
    "print(best_opt, best_eval, \"/\", best_loss_opt, best_loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4e4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46600b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_env_kernel",
   "language": "python",
   "name": "all_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
